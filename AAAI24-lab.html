<!DOCTYPE html>
<!--[if IE 8 ]>
<html class="no-js oldie ie8" lang="en"> <![endif]-->
<!--[if IE 9 ]>
<html class="no-js oldie ie9" lang="en"> <![endif]-->
<!--[if (gte IE 9)|!(IE)]><!-->
<html> <!--<![endif]-->
<head>
  <meta name="viewport" content="width=device-width, initial-scale=1">
<style>

.container {
  margin-left: auto;
  margin-right: auto;
  display: flex;
  align-items: center;
  justify-content: center
}

table {
  font-family: arial, sans-serif;
  border-collapse: collapse;
  width: 80%;
  margin-left: auto;
  margin-right: auto;
}

td, th {
  border: 1px solid #dddddd;
  text-align: left;
  padding: 8px;
}

tr:nth-child(even) {
  background-color: #dddddd;
}

  
body, html {
  height: 100%;
  margin: 0;
  font-family: Arial, Helvetica, sans-serif;
}

.hero-image {
  background-image: linear-gradient(rgba(0, 0, 0, 0.5), rgba(0, 0, 0, 0.5)), url("images/banner2.png");
  height: 50%;
  background-position: center;
  background-repeat: no-repeat;
  background-size: cover;
  position: relative;
}

.hero-text {
  text-align: center;
  position: absolute;
  top: 50%;
  left: 50%;
  transform: translate(-50%, -50%);
  color: white;
}

.hero-text button {
  border: none;
  outline: 0;
  display: inline-block;
  padding: 10px 25px;
  color: black;
  background-color: #ddd;
  text-align: center;
  cursor: pointer;
}

.hero-text button:hover {
  background-color: #555;
  color: white;
}

.section-head-text {
  color: rgba(56, 66, 78, 0.5);
  text-align: center; 
  font-size: 1.6rem;
  line-height: 1.875;
  margin-bottom: 0.3rem;
  letter-spacing: .1rem;
}

.section-text {
  margin-left: auto;
  margin-right: auto;
  width:65%;
  margin-bottom: 0.1rem;
  word-wrap: break-all;
}
</style>

  
</head>

<body>

<div class="hero-image">
  <div class="hero-text">
    <h1 style="font-size:50px">LH2: Introduction to MDP Modeling and Interaction via RDDL and pyRDDLGym</h1>
    <p>AAAI-2024 Vancouver</p>
  </div>
</div>

<section>
  <div class="section-head-text">
    <h2>Overview</h2>
  </div>
  <div class="section-text">
    <p>
      RDDL (pronounced as “riddle”) stands for the Relational Dynamic Influence Diagram Language. 
      It is the domain modeling language utilized in the International Conference on Automated Planning and Scheduling (ICAPS) in the years 2011, 2014, 2018, 
      and most recently in 2023 for the Probabilistic Planning and Reinforcement Learning track of the International Planning Competitions. 
      RDDL was designed to efficiently represent real-world stochastic planning problems, specifically Markov Decision Processes (MDPs), with a focus on factored MDPs characterized by highly structured transition and reward functions. 
      This tutorial aims to provide basic understanding of RDDL, including recent language enhancements and features, through a practical example. 
      We will introduce a problem based on a real-world scenario and incrementally build up its representation in RDDL, starting from the raw mathematical equations up to a full RDDL description. 
      Furthermore, we will introduce “pyRDDLGym,” a new Python framework for the generation of Gym environments from RDDL descriptions. 
      This facilitates interaction with Reinforcement Learning (RL) agents via the standard Gym interface, as well as enables planning agents to work with the model. 
      In a series of exercises, we will explore the capabilities of pyRDDLGym, which includes generation of the Dynamic Bayesian Networks (DBN) and eXtended Algebraic Decision Diagrams (XADD)-based conditional probability functions, 
      as well as offering both generic and custom visualization options. We will also generate a functional environment for the example problem. 
      To close the loop from a mathematical representation to a fully operational policy, we will utilize the built-in model-based anytime backpropagation planner, 
      known as “JaxPlan.” This will enable us to obtain solutions for the example problem, effectively closing the gap between theoretical description and a practical working policy.
    </p>
  </div>
</section>

<section>
  <div class="section-head-text">
    <h2>Outline</h2>
  </div>
  <div class="section-text">
    <ul>
      <li>Introduction to stochastic planning problem classes and languages</li>
          <ul>
            <li>General overview</li>
            <li>MDP and stochastic problems with introduction of a running example</li>
            <li>POMDP extensions</li>
          </ul>
      <li>RDDL overview</li>
          <ul>
            <li>Language overview capabilities</li>
            <li>Domain and problem components</li>
            <li>Modeling of the running example in RDDL (grounded)</li>
            <li>Scaling up by lifting the domain specification</li>
          </ul>
      <li>Introduction to pyRDDLGym</li>
        <ul>
          <li>Vision</li>
          <li>Repository structure</li>
          <li>Executing the running example with the built-in visualizer and a simple policy</li>
          <li>Custom visualization</li>
          <li>Auxiliary (diagnostic) tools</li>
        </ul>
      
      <li>Hands-on and interactive exercises</li>
        <ul>
          <li>Mathematical modeling</li>
          <li>RDDL representation</li>
          <li>Interaction with a simple agent</li>
          <li>Extending the model</li>
          <li>Scalling up from one to many in a heart beat</li>
          <li>Using the model based solver JaxPlan</li>
          <li>Applying RL tools in pyRDDLGym</li>
        </ul>
    </ul>
  </div>
  <p></p>
</section>

<section>
  <div class="section-head-text">
    <h2>Schedule</h2>
  </div>
  <div class="section-text">
      <table>
        <tr>
          <th>Time</th>
          <th>Topic</th>
        </tr>
        <tr>
          <td>8:30-9:30am</th>
          <td>Introduction to stochastic planning problem classes and languages</th>
        </tr>
        <tr>
          <td>9:30-10:00am</td>
          <td>RDDL overview</td>
        </tr>
        <tr>
          <td>10:00-10:30am</td>
          <td>Introduction to pyRDDLGym</td>
        </tr>
        <tr>
          <td>10:30am-11:00am</td>
          <td>Break</td>
        </tr>
        <tr>
          <td>11:00am-12:30pm</td>
          <td>Hands-on and interactive exercises</td>
        </tr>
      </table>
  </div>
</section>
  
<section>
  <div class="section-head-text">
    <h2>Audience</h2>
  </div>
  <div class="section-text">
    <ul>
      <li><b>Target audience:</b> Machine learning and applied math researchers and practitioners.</li>
      <li><b>Prerequisite knowledge:</b> The audience is assumed to have basic knowledge of Markov Decision Processes (MDPs) 
          (e.g., through Reinforcement Learning or Planning), a basic knowledge of Python, and preferably (though not required) a familiarity with OpenAI Gym environment.</li>
    </ul>  
  </div>
</section>
  
<section>
  <div class="section-head-text">
    <h2>Organizers</h2>
  </div>
  <div class="container">
    <div class="section-text">
      <img src="https://aaai.org/wp-content/uploads/2023/11/Scott_Sanner_White_Background.png" width="168" height="201">
      <p><b>Scott Sanner</b></p>
      <p>Scott Sanner is an Associate Professor at the University of Toronto specializing in AI topics such as sequential decision-making, recommender systems, and machine/deep learning applications. 
        He is an Associate Editor for three journals and a recipient of four paper awards and a Google Faculty Research Award</p>
    </div>
    <div class="section-text">
      <img src="https://aaai.org/wp-content/uploads/2023/11/Ayal-white-background.png" width="168" height="201">
      <p style="text-align=center"><b>Ayal Taitler</b></p>
      <p>Ayal Taitler is a Postdoctoral Fellow at the University of Toronto, working with Prof. Scott Sanner. His research interests lie at the intersection of reinforcement learning, 
        automated planning, and control theory, and its application to robotics and intelligent transportation. With over 10 years of experience in software engineering and AI research.</p>
    </div>
  </div>
</section>
  

</body>
</html>


  
